{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'batch_size': 16,\n",
    "    'embedding_dim': 256,\n",
    "    'lstm_out_dim': 512,\n",
    "    'epochs': 150,\n",
    "    'learning_rate': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/scratch/lt2316-h18-resources/coco/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=21.90s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_captions = COCO(BASE_PATH + 'annotations/captions_train2017.json')\n",
    "coco_instances = COCO(BASE_PATH + 'annotations/instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'license': 3,\n",
       "  'file_name': '000000391895.jpg',\n",
       "  'coco_url': 'http://images.cocodataset.org/train2017/000000391895.jpg',\n",
       "  'height': 360,\n",
       "  'width': 640,\n",
       "  'date_captured': '2013-11-14 11:18:45',\n",
       "  'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg',\n",
       "  'id': 391895}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(coco_captions.imgs.values())[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, coco_captions, number_of_samples=100, train_split=0.8, val_split=0.05, test_split=0.15) -> None:\n",
    "        samples = []\n",
    "        random_images = random.sample(list(coco_captions.imgs.values()), number_of_samples)\n",
    "        for image_info in random_images:\n",
    "            image = Image.open(BASE_PATH + 'train2017/' + image_info['file_name'])\n",
    "            samples.append({\n",
    "                'image': list(image.getdata()),\n",
    "                'annotations': [annotation['caption']\n",
    "                                for annotation in coco_captions.imgToAnns[image_info['id']]]\n",
    "            })\n",
    "\n",
    "        train_border = int(train_split * number_of_samples)\n",
    "        val_border = int((train_split + val_split) * number_of_samples)\n",
    "\n",
    "        self.train_samples = samples[:train_border]\n",
    "        self.val_samples = samples[train_border:val_border]\n",
    "        self.test_samples = samples[val_border:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCO_Dataset(Dataset):\n",
    "    def __init__(self, samples) -> None:\n",
    "        super().__init__()\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(coco_captions)\n",
    "\n",
    "train_dataloader = DataLoader(COCO_Dataset(sampler.train_samples),\n",
    "                              batch_size=hyperparameters['batch_size'],\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(COCO_Dataset(sampler.val_samples),\n",
    "                            batch_size=hyperparameters['batch_size'],\n",
    "                            shuffle=True)\n",
    "test_dataloader = DataLoader(COCO_Dataset(sampler.test_samples),\n",
    "                             batch_size=hyperparameters['batch_size'],\n",
    "                             shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('lt2326_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd2feef55d4ee460479306887fa1cc2179f52f92e40ccb13d5bbd3870fa5c6f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
