{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe\n",
    "from nltk.tokenize import word_tokenize\n",
    "from model import CaptionEncoder, ImageEncoder, CaptionEvaluator, train\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/scratch/lt2316-h18-resources/coco/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_captions = COCO(BASE_PATH + 'annotations/captions_train2017.json')\n",
    "# coco_instances = COCO(BASE_PATH + 'annotations/instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I added the <PAD> and <UNK> token to the glove vectors initialized with zeros\n",
    "glove_vectors = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400002, 300])\n"
     ]
    }
   ],
   "source": [
    "print(glove_vectors.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'number_of_images': 10000,\n",
    "    'batch_size': 32,\n",
    "    # embedding dim -1 will initialize with glove vectors\n",
    "    'embedding_dim': -1,\n",
    "    'lstm_out_dim': 512,\n",
    "    'lstm_layers': 1,\n",
    "    'hidden_size': 2000,\n",
    "    'epochs': 25,\n",
    "    'learning_rate': 0.0002\n",
    "}\n",
    "\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "UNKNOWN_TOKEN = '<UNK>'\n",
    "\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, coco_captions, number_of_samples=100, negative_sample_split=0.95, train_split=0.8, val_split=0.05, test_split=0.15) -> None:\n",
    "        samples = []\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        random_images = random.sample(list(coco_captions.imgs.values()), number_of_samples)\n",
    "        CAPTIONS_PER_IMAGE = len(coco_captions.imgToAnns[random_images[0]['id']])\n",
    "\n",
    "        for image_info in random_images:\n",
    "            image = Image.open(BASE_PATH + 'train2017/' + image_info['file_name']).resize((100,100)).convert('RGB')\n",
    "            samples.extend([{\n",
    "                'image': transform(image),\n",
    "                'caption': annotation['caption'].lower(),\n",
    "                'class': 1         \n",
    "            } for annotation in coco_captions.imgToAnns[image_info['id']]])\n",
    "\n",
    "        self.max_length_context = max([len(word_tokenize(sample['caption'])) for sample in samples])\n",
    "\n",
    "        samples.extend([{\n",
    "            'image': sample['image'],\n",
    "            'caption': samples[index - CAPTIONS_PER_IMAGE]['caption'],\n",
    "            'class': 0\n",
    "        } for index, sample in enumerate(samples[CAPTIONS_PER_IMAGE:int(CAPTIONS_PER_IMAGE * negative_sample_split * number_of_samples)])])\n",
    "\n",
    "        random.shuffle(samples)\n",
    "\n",
    "        train_border = int(train_split * len(samples))\n",
    "        val_border = int((train_split + val_split) * len(samples))\n",
    "\n",
    "        self.train_samples = samples[:train_border]\n",
    "        self.val_samples = samples[train_border:val_border]\n",
    "        self.test_samples = samples[val_border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCO_Dataset(Dataset):\n",
    "    def __init__(self, samples, max_length_context, dataset=None) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_length_context = max_length_context\n",
    "\n",
    "        if dataset is None:\n",
    "            vocab = {PADDING_TOKEN, UNKNOWN_TOKEN}\n",
    "            for sample in samples:\n",
    "                split_caption = word_tokenize(sample['caption'])\n",
    "                vocab.update(split_caption)\n",
    "\n",
    "            self.vocab = {word: index for index, word in enumerate(list(vocab))}\n",
    "        else:\n",
    "            self.vocab = dataset.vocab\n",
    "\n",
    "        self.samples = []\n",
    "        for sample in samples:\n",
    "            split_caption = word_tokenize(sample['caption'])\n",
    "            padded_context = [self.get_encoded_word(word) for word in split_caption]\n",
    "            padded_context.extend([self.get_encoded_word(PADDING_TOKEN)] * (self.max_length_context - len(split_caption)))\n",
    "\n",
    "            glove_context = [glove_vectors.stoi[word] if word in glove_vectors.itos else glove_vectors.stoi[UNKNOWN_TOKEN] for word in split_caption]\n",
    "            glove_context.extend([glove_vectors.stoi[PADDING_TOKEN]] * (self.max_length_context - len(split_caption)))\n",
    "\n",
    "            self.samples.append({\n",
    "                'image': sample['image'],\n",
    "                'caption': sample['caption'],\n",
    "                'encoded_caption': torch.tensor(padded_context),\n",
    "                'glove_encoded_caption': torch.tensor(glove_context),\n",
    "                'class': torch.tensor(sample['class'], dtype=torch.float)\n",
    "            })\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.samples[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get_encoded_word(self, word):\n",
    "        if word in self.vocab:\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            return self.vocab[UNKNOWN_TOKEN]\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(coco_captions,hyperparameters['number_of_images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = COCO_Dataset(sampler.train_samples, sampler.max_length_context)\n",
    "val_dataset = COCO_Dataset(sampler.val_samples, sampler.max_length_context, train_dataset)\n",
    "test_dataset = COCO_Dataset(sampler.test_samples, sampler.max_length_context, train_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=hyperparameters['batch_size'],\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=hyperparameters['batch_size'],\n",
    "                            shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=hyperparameters['batch_size'],\n",
    "                             shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives: 37943\n",
      "positives: 40078\n"
     ]
    }
   ],
   "source": [
    "positives = 0\n",
    "negatives = 0\n",
    "for sample in train_dataloader.dataset:\n",
    "    if sample['class'] == 1:\n",
    "        positives += 1\n",
    "    else:\n",
    "        negatives += 1\n",
    "print(f'negatives: {negatives}')\n",
    "print(f'positives: {positives}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 EPOCHS - 2438 BATCHES PER EPOCH\n",
      "epoch 0, batch 2438: 0.6978\n",
      "epoch 1, batch 2438: 0.6544\n",
      "epoch 2, batch 2438: 0.5843\n",
      "epoch 3, batch 2438: 0.5037\n",
      "epoch 4, batch 2438: 0.4139\n",
      "epoch 5, batch 2438: 0.3187\n",
      "epoch 6, batch 2438: 0.2413\n",
      "epoch 7, batch 2438: 0.1869\n",
      "epoch 8, batch 2438: 0.2719\n",
      "epoch 9, batch 2438: 0.1734\n",
      "epoch 10, batch 2438: 0.1328\n",
      "epoch 11, batch 2438: 0.1098\n",
      "epoch 12, batch 2438: 0.0995\n",
      "epoch 13, batch 2438: 0.0796\n",
      "epoch 14, batch 2438: 0.0701\n",
      "epoch 15, batch 2438: 0.0587\n",
      "epoch 16, batch 2438: 0.0571\n",
      "epoch 17, batch 2438: 0.0507\n",
      "epoch 18, batch 2438: 0.0455\n",
      "epoch 19, batch 2438: 0.0439\n",
      "epoch 20, batch 2438: 0.0383\n",
      "epoch 21, batch 2438: 0.0363\n",
      "epoch 22, batch 2438: 0.0354\n",
      "epoch 23, batch 2438: 0.0329\n",
      "epoch 24, batch 2438: 0.0307\n"
     ]
    }
   ],
   "source": [
    "caption_encoder = CaptionEncoder(train_dataloader.dataset.get_vocab_size(),\n",
    "                                 hyperparameters['embedding_dim'],\n",
    "                                 hyperparameters['lstm_out_dim'],\n",
    "                                 hyperparameters['lstm_layers'],\n",
    "                                 train_dataloader.dataset.get_encoded_word(PADDING_TOKEN),\n",
    "                                 glove_vectors)\n",
    "\n",
    "image_encoder = ImageEncoder()\n",
    "caption_evaluator = CaptionEvaluator(caption_encoder,\n",
    "                                     image_encoder, \n",
    "                                     hyperparameters['hidden_size'])\n",
    "\n",
    "caption_evaluator.to(device)\n",
    "\n",
    "train(caption_evaluator, train_dataloader, hyperparameters, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_evaluator.eval()\n",
    "\n",
    "predictions = []\n",
    "gold_classes = []\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        predictions.extend(caption_evaluator(batch['image'].to(device), batch['glove_encoded_caption'].to(device)).view(len(batch['image'])))\n",
    "    \n",
    "    gold_classes.extend(batch['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- THRESHOLD: 0.1 ---\n",
      "Accuracy: 0.9477101845522898\n",
      "Precision: 0.9799918886034878\n",
      "Recall: 0.9215611492499365\n",
      "F1-Score: 0.9498787918495709\n",
      "--- THRESHOLD: 0.2 ---\n",
      "Accuracy: 0.9535201640464799\n",
      "Precision: 0.9726916317425983\n",
      "Recall: 0.937703636126678\n",
      "F1-Score: 0.9548772395487723\n",
      "--- THRESHOLD: 0.3 ---\n",
      "Accuracy: 0.9559125085440875\n",
      "Precision: 0.9676896038934704\n",
      "Recall: 0.9463246959280803\n",
      "F1-Score: 0.9568879085622619\n",
      "--- THRESHOLD: 0.4 ---\n",
      "Accuracy: 0.956390977443609\n",
      "Precision: 0.962146816276869\n",
      "Recall: 0.9521070234113712\n",
      "F1-Score: 0.9571005917159764\n",
      "--- THRESHOLD: 0.5 ---\n",
      "Accuracy: 0.9565276828434723\n",
      "Precision: 0.957144788427741\n",
      "Recall: 0.9568860656845519\n",
      "F1-Score: 0.9570154095701541\n",
      "--- THRESHOLD: 0.6 ---\n",
      "Accuracy: 0.9566643882433357\n",
      "Precision: 0.9521427605786129\n",
      "Recall: 0.9617643042468933\n",
      "F1-Score: 0.9569293478260869\n",
      "--- THRESHOLD: 0.7 ---\n",
      "Accuracy: 0.9553656869446343\n",
      "Precision: 0.9449776936595917\n",
      "Recall: 0.9660033167495854\n",
      "F1-Score: 0.9553748376956195\n",
      "--- THRESHOLD: 0.8 ---\n",
      "Accuracy: 0.9535201640464799\n",
      "Precision: 0.9357847776125456\n",
      "Recall: 0.9712361442402133\n",
      "F1-Score: 0.9531809418892867\n",
      "--- THRESHOLD: 0.9 ---\n",
      "Accuracy: 0.9479835953520164\n",
      "Precision: 0.918886034879005\n",
      "Recall: 0.9768611670020121\n",
      "F1-Score: 0.9469871125043539\n"
     ]
    }
   ],
   "source": [
    "CLASS_THRESHOLD = []\n",
    "for threshold in range(1, 10):\n",
    "    predicted_classes = []\n",
    "    predicted_classes.extend([1 if sample > threshold / 10 else 0 for sample in predictions])\n",
    "    print(f'--- THRESHOLD: {threshold / 10} ---')\n",
    "    print(f'Accuracy: {accuracy_score(predicted_classes, gold_classes)}')\n",
    "    print(f'Precision: {precision_score(predicted_classes, gold_classes)}')\n",
    "    print(f'Recall: {recall_score(predicted_classes, gold_classes)}')\n",
    "    print(f'F1-Score: {f1_score(predicted_classes, gold_classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('caption_encoder.embeddings.weight',\n",
       "              tensor([[ 1.3523e-02,  1.8526e-01,  7.2809e-03,  ...,  1.9830e-02,\n",
       "                       -2.3915e-01,  5.6054e-02],\n",
       "                      [-3.1423e-01, -2.7642e-01,  1.3203e-01,  ..., -2.0023e-01,\n",
       "                       -1.7323e-01,  3.9787e-01],\n",
       "                      [-1.3877e-01,  5.6329e-02,  9.6273e-02,  ..., -3.6058e-01,\n",
       "                       -2.7464e-02,  1.1599e-01],\n",
       "                      ...,\n",
       "                      [ 4.2919e-01, -2.9690e-01,  1.5011e-01,  ...,  2.8975e-01,\n",
       "                        3.2618e-01, -5.9053e-02],\n",
       "                      [ 1.2275e-05, -1.5291e-02, -2.7391e-03,  ..., -8.3573e-03,\n",
       "                        1.4206e-02, -1.2602e-02],\n",
       "                      [ 3.6148e-02, -3.5777e-03,  1.0486e-02,  ..., -5.0656e-02,\n",
       "                        2.7047e-02, -1.5744e-02]], device='cuda:2')),\n",
       "             ('caption_encoder.rnn.weight_ih_l0',\n",
       "              tensor([[ 0.0219, -0.0235, -0.0567,  ...,  0.0527,  0.0581, -0.0328],\n",
       "                      [ 0.0034, -0.0012, -0.0144,  ...,  0.0372, -0.0017, -0.0442],\n",
       "                      [ 0.0045,  0.0630, -0.0368,  ..., -0.0435, -0.0079, -0.0436],\n",
       "                      ...,\n",
       "                      [ 0.0531, -0.0089,  0.0373,  ...,  0.0005,  0.0147, -0.0384],\n",
       "                      [-0.0088, -0.0648, -0.0341,  ...,  0.0663, -0.0535, -0.0249],\n",
       "                      [ 0.0713, -0.0047, -0.0223,  ...,  0.0048, -0.0400,  0.0800]],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.weight_hh_l0',\n",
       "              tensor([[-0.0243, -0.0367, -0.0864,  ..., -0.0186, -0.0210,  0.1616],\n",
       "                      [ 0.0602,  0.0594, -0.1092,  ..., -0.0170,  0.0010,  0.1669],\n",
       "                      [ 0.0466, -0.0214, -0.0637,  ..., -0.0054, -0.0057,  0.0904],\n",
       "                      ...,\n",
       "                      [ 0.0303,  0.0653, -0.0768,  ..., -0.0521, -0.0247,  0.1135],\n",
       "                      [-0.0438,  0.0717,  0.0342,  ..., -0.0873, -0.0338,  0.0217],\n",
       "                      [-0.0293,  0.0420, -0.0996,  ..., -0.0958, -0.0700,  0.0242]],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.bias_ih_l0',\n",
       "              tensor([-0.1430, -0.1924, -0.0434,  ..., -0.2355, -0.2770, -0.0806],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.bias_hh_l0',\n",
       "              tensor([-0.1344, -0.2219, -0.0277,  ..., -0.1752, -0.3443, -0.0452],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.0436, -0.0999, -0.0765,  ...,  0.1324, -0.1000,  0.0276],\n",
       "                      [-0.0149, -0.0369,  0.0447,  ...,  0.1527, -0.0690,  0.0358],\n",
       "                      [ 0.1684, -0.0836, -0.0474,  ..., -0.0393,  0.0151,  0.1170],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0289,  0.0162,  ...,  0.0523, -0.0482,  0.0100],\n",
       "                      [ 0.0775, -0.0366, -0.0759,  ...,  0.0808,  0.0226,  0.0329],\n",
       "                      [ 0.1020, -0.0613, -0.0473,  ..., -0.0556,  0.0038,  0.0260]],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0158, -0.0121,  0.0363,  ..., -0.0520,  0.0396, -0.0803],\n",
       "                      [-0.0184, -0.0045,  0.0447,  ..., -0.0274, -0.0154, -0.0608],\n",
       "                      [-0.0220, -0.0204,  0.0842,  ..., -0.0805,  0.0336,  0.0567],\n",
       "                      ...,\n",
       "                      [ 0.0323, -0.0282, -0.1256,  ...,  0.0479, -0.0130,  0.0389],\n",
       "                      [ 0.0694,  0.0784, -0.0905,  ..., -0.1080,  0.0806, -0.0017],\n",
       "                      [-0.0380, -0.0212,  0.0027,  ..., -0.0772,  0.0740, -0.0520]],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.bias_ih_l0_reverse',\n",
       "              tensor([ 0.0162, -0.0057, -0.0688,  ...,  0.0443,  0.0824, -0.0150],\n",
       "                     device='cuda:2')),\n",
       "             ('caption_encoder.rnn.bias_hh_l0_reverse',\n",
       "              tensor([ 0.0283, -0.0330, -0.0828,  ..., -0.0094,  0.0375,  0.0247],\n",
       "                     device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.0.weight',\n",
       "              tensor([[[[ 0.1391,  0.0232,  0.0530],\n",
       "                        [ 0.1277,  0.0455,  0.0349],\n",
       "                        [-0.0477,  0.1621, -0.1131]],\n",
       "              \n",
       "                       [[ 0.0024, -0.0338, -0.2007],\n",
       "                        [-0.0193, -0.2184, -0.1422],\n",
       "                        [ 0.0021, -0.0715, -0.1558]],\n",
       "              \n",
       "                       [[ 0.0793, -0.0937, -0.0275],\n",
       "                        [ 0.0199,  0.0852, -0.0878],\n",
       "                        [ 0.1806, -0.1615,  0.0926]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0645, -0.2154,  0.0669],\n",
       "                        [-0.1247, -0.2122,  0.0576],\n",
       "                        [-0.0350,  0.0157,  0.1732]],\n",
       "              \n",
       "                       [[-0.1159,  0.0846,  0.0376],\n",
       "                        [-0.1133, -0.0811,  0.1918],\n",
       "                        [ 0.0021,  0.0763, -0.0404]],\n",
       "              \n",
       "                       [[ 0.0701,  0.0169, -0.1259],\n",
       "                        [ 0.1390, -0.0441,  0.1892],\n",
       "                        [-0.1212, -0.1137,  0.1453]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1238, -0.0205,  0.1452],\n",
       "                        [ 0.1388, -0.0755, -0.0306],\n",
       "                        [ 0.1119,  0.0094,  0.1170]],\n",
       "              \n",
       "                       [[-0.1546,  0.1998, -0.1567],\n",
       "                        [ 0.0579, -0.0317,  0.1881],\n",
       "                        [ 0.2487, -0.0475, -0.0462]],\n",
       "              \n",
       "                       [[-0.2365, -0.0900, -0.1452],\n",
       "                        [ 0.0351, -0.0371, -0.0610],\n",
       "                        [-0.1085,  0.1033,  0.0682]]]], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.0.bias',\n",
       "              tensor([-0.1432, -0.0458,  0.0134], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.1.weight',\n",
       "              tensor([0.8489, 0.9512, 1.0005], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.1.bias',\n",
       "              tensor([-0.4049, -0.5087, -0.4226], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.1.running_mean',\n",
       "              tensor([-0.2837, -0.1200,  0.0613], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.1.running_var',\n",
       "              tensor([0.0141, 0.0080, 0.0082], device='cuda:2')),\n",
       "             ('image_encoder.image_encoder.1.num_batches_tracked',\n",
       "              tensor(60975, device='cuda:2')),\n",
       "             ('classifier.0.weight',\n",
       "              tensor([[ 0.0196, -0.0406,  0.0514,  ...,  0.0222, -0.0065, -0.0427],\n",
       "                      [-0.0326, -0.0166,  0.0112,  ...,  0.0799,  0.0222,  0.0486],\n",
       "                      [-0.0012,  0.0237, -0.0237,  ..., -0.0247,  0.0183,  0.0067],\n",
       "                      ...,\n",
       "                      [-0.0780,  0.0561,  0.1356,  ...,  0.0021, -0.0498, -0.0448],\n",
       "                      [ 0.0062,  0.0011,  0.0759,  ...,  0.0436,  0.0130,  0.0243],\n",
       "                      [ 0.0198, -0.0688,  0.0207,  ...,  0.0208,  0.0163,  0.0895]],\n",
       "                     device='cuda:2')),\n",
       "             ('classifier.0.bias',\n",
       "              tensor([ 0.0549,  0.0284, -0.0325,  ...,  0.0452,  0.0293,  0.0690],\n",
       "                     device='cuda:2')),\n",
       "             ('classifier.3.weight',\n",
       "              tensor([[-0.0382,  0.0808,  0.0152,  ..., -0.0149, -0.0102, -0.0132],\n",
       "                      [ 0.0160,  0.0135,  0.0150,  ...,  0.0150,  0.0119,  0.0075],\n",
       "                      [ 0.0060,  0.0465,  0.0583,  ..., -0.0429, -0.0163, -0.0554],\n",
       "                      ...,\n",
       "                      [-0.0962, -0.0113, -0.0528,  ...,  0.0439,  0.0155,  0.0320],\n",
       "                      [-0.0776,  0.0219, -0.0084,  ...,  0.0099, -0.0391, -0.0213],\n",
       "                      [-0.0545, -0.0517,  0.0306,  ..., -0.0265, -0.0248, -0.0369]],\n",
       "                     device='cuda:2')),\n",
       "             ('classifier.3.bias',\n",
       "              tensor([ 6.8179e-02, -4.1346e-02,  6.5761e-02,  5.9715e-02,  2.8725e-02,\n",
       "                      -3.2538e-02,  1.0141e-02, -4.8539e-04,  1.2184e-01,  3.6317e-02,\n",
       "                       1.9982e-02, -1.3970e-02, -3.1303e-02, -5.5373e-02, -3.5212e-02,\n",
       "                      -3.1267e-02,  1.4721e-02, -1.9718e-02,  1.4257e-02,  6.3715e-02,\n",
       "                       4.6038e-02, -1.2496e-04, -4.3336e-03, -4.6525e-03,  8.4968e-03,\n",
       "                      -1.1597e-02, -2.6644e-02, -1.0550e-02,  5.4283e-02, -2.8592e-03,\n",
       "                       8.4270e-03, -1.7361e-02,  7.5565e-03,  1.2986e-02,  8.3552e-03,\n",
       "                      -3.5409e-02,  1.0031e-02, -3.6530e-02, -4.5497e-03,  6.2311e-02,\n",
       "                       1.0227e-02,  3.0380e-03,  6.1699e-02, -1.3910e-02, -3.6719e-02,\n",
       "                      -3.3360e-02, -4.4164e-02,  3.1999e-02,  6.8320e-03, -3.9774e-02,\n",
       "                       3.9107e-02, -2.6329e-02,  9.0476e-02,  3.5444e-02, -4.7364e-02,\n",
       "                       3.1915e-03,  1.4126e-01,  4.6740e-02, -5.8449e-02,  1.2924e-01,\n",
       "                      -7.2599e-02, -5.7068e-02, -4.3750e-02,  8.1128e-02, -7.3353e-02,\n",
       "                      -2.7209e-02,  1.6360e-03, -1.2353e-02, -6.8823e-03,  2.4583e-02,\n",
       "                      -4.7553e-02, -2.6616e-03,  4.2532e-02, -5.5424e-03, -3.8878e-02,\n",
       "                      -3.0455e-02, -3.6552e-02,  2.1373e-02, -9.5165e-03, -2.8969e-02,\n",
       "                      -2.8329e-02, -8.9547e-03,  6.1777e-02,  1.8040e-02,  5.0482e-03,\n",
       "                      -2.0548e-02, -3.5188e-03, -7.6105e-02,  3.7685e-02, -4.4455e-02,\n",
       "                      -2.2947e-02,  4.2788e-02,  3.0011e-02, -4.2459e-02, -3.3829e-03,\n",
       "                      -2.5457e-02,  2.6362e-02, -4.3539e-02, -5.5596e-02, -9.2061e-03,\n",
       "                       7.9145e-02,  2.8401e-02,  3.4281e-02, -5.9200e-02,  3.5001e-03,\n",
       "                       3.2526e-02,  1.7762e-02, -4.9214e-02, -6.4397e-02, -5.6460e-02,\n",
       "                      -1.4948e-02, -4.0844e-02,  2.0515e-02, -3.3692e-02,  1.6226e-02,\n",
       "                       3.8964e-02,  3.2369e-02, -6.3751e-03, -5.4784e-02,  5.9221e-02,\n",
       "                       2.5259e-02, -5.0432e-02,  4.8581e-02,  1.2744e-02, -1.8600e-02,\n",
       "                       2.4848e-02,  9.3237e-02, -3.2862e-03,  3.5982e-02, -8.7810e-03,\n",
       "                       1.2316e-02,  4.4980e-02,  3.7561e-02, -6.7998e-03,  2.6989e-02,\n",
       "                       2.5780e-02,  1.1492e-02,  6.9595e-02,  6.5736e-02,  4.3709e-02,\n",
       "                      -1.6953e-02,  8.0821e-03,  4.8882e-02, -4.7336e-02, -4.3640e-03,\n",
       "                      -5.6973e-02, -7.3949e-02,  2.3019e-02,  1.3172e-02,  4.1775e-02,\n",
       "                      -3.3031e-02,  2.7184e-02, -4.2119e-02, -2.7694e-02,  4.0766e-02,\n",
       "                      -1.7530e-02,  3.8894e-02, -5.3030e-02, -2.3386e-02, -1.4879e-02,\n",
       "                       1.6468e-02, -9.1741e-02,  1.5690e-02,  7.3589e-03, -2.5243e-02,\n",
       "                      -1.5440e-03, -4.7757e-02,  4.4554e-02,  1.3111e-02, -3.3298e-03,\n",
       "                       4.2941e-03, -4.5049e-02, -2.7511e-02,  8.6851e-02,  3.7559e-03,\n",
       "                       5.0685e-02, -7.6735e-02, -6.2859e-02,  4.5387e-02, -3.9231e-02,\n",
       "                       3.1792e-02, -6.9793e-02, -1.2679e-02, -1.8295e-02,  3.4359e-02,\n",
       "                       3.4069e-02,  7.7371e-03,  2.8102e-03, -7.5816e-02, -7.9481e-03,\n",
       "                       4.2666e-03,  6.6421e-02, -2.7738e-02,  6.3519e-02,  2.0481e-02,\n",
       "                      -1.1129e-03, -4.1780e-03,  3.0572e-03, -6.3995e-05, -3.8492e-02,\n",
       "                      -2.8236e-02, -2.0132e-02,  6.7617e-02, -2.2274e-02,  1.0552e-02,\n",
       "                       3.0869e-02, -3.2485e-02,  1.7628e-02,  1.7434e-02, -5.5676e-03,\n",
       "                      -2.9772e-02, -2.0004e-02,  3.6850e-02, -1.9270e-02,  3.6769e-02,\n",
       "                      -4.5942e-02, -2.9766e-02,  2.6362e-02, -9.5348e-03,  1.8509e-02,\n",
       "                      -3.0000e-02,  4.3247e-02,  5.6578e-02,  3.8287e-02,  1.8046e-02,\n",
       "                      -4.5628e-02, -4.3331e-03,  1.5169e-02, -4.2445e-02, -2.7596e-04,\n",
       "                      -3.4527e-02, -4.3505e-02, -7.6358e-02,  1.5042e-02, -8.7451e-04,\n",
       "                       4.4560e-02,  2.8750e-02,  1.0135e-02,  2.6497e-03,  7.0818e-02,\n",
       "                       2.0611e-02,  3.0289e-02, -1.6900e-03, -4.1385e-03, -3.7433e-02,\n",
       "                      -7.6040e-03, -4.5744e-02,  4.9398e-02, -4.0630e-02,  2.2903e-02,\n",
       "                      -3.0087e-02,  7.1739e-02,  6.6540e-02,  8.6464e-02, -2.7572e-03,\n",
       "                       4.8583e-02, -2.0114e-02, -1.6963e-02, -1.2106e-03, -3.1055e-03,\n",
       "                      -9.4410e-03,  6.7924e-03,  3.9477e-02,  1.0326e-02,  7.6016e-03,\n",
       "                       2.9015e-03, -8.2499e-02,  3.2638e-02, -4.8490e-02,  3.8059e-02,\n",
       "                      -3.7783e-02, -3.5148e-02, -6.2908e-03,  5.2814e-03,  1.5559e-03,\n",
       "                       2.3170e-02,  4.3074e-02, -4.7930e-02,  6.4044e-02,  5.8981e-02,\n",
       "                       1.0734e-02,  3.7507e-02, -7.5160e-03,  4.3722e-02, -3.8987e-02,\n",
       "                       6.4660e-02,  8.1091e-03, -2.4648e-02,  1.3790e-02,  4.3070e-02,\n",
       "                      -5.5826e-02,  5.1621e-02,  2.6542e-02, -2.5309e-02, -3.6271e-02,\n",
       "                       1.7297e-02, -9.9702e-03, -4.1367e-02, -2.5626e-02,  2.3326e-02,\n",
       "                      -1.6186e-02, -2.2395e-02, -5.8404e-02, -4.7632e-02,  3.9774e-02,\n",
       "                      -4.6571e-02,  6.6936e-02,  1.3446e-02, -7.4166e-03,  6.3582e-02,\n",
       "                       7.1730e-03,  8.6766e-02,  4.4624e-02, -1.3770e-02, -9.8588e-02,\n",
       "                      -4.9648e-02,  8.1503e-02,  8.8364e-02,  3.2840e-02,  2.4302e-02,\n",
       "                       2.3404e-02,  6.1822e-02, -1.4768e-02, -8.8744e-03,  6.7760e-02,\n",
       "                       3.4050e-02, -3.0614e-02,  1.1128e-02,  1.5856e-02, -7.6625e-03,\n",
       "                      -1.2660e-02,  4.4199e-02, -2.9057e-02,  2.6521e-03,  4.6150e-03,\n",
       "                       2.0048e-02,  2.2807e-02,  1.1224e-03, -2.7156e-02, -1.1766e-01,\n",
       "                      -3.8905e-02,  2.6879e-02,  1.3448e-02,  1.6141e-02,  2.0618e-02,\n",
       "                       3.1952e-03, -2.5719e-02, -4.8301e-02,  4.2486e-02,  6.2554e-02,\n",
       "                      -3.7747e-02, -4.0943e-02,  1.2940e-02, -3.8078e-02,  2.1605e-02,\n",
       "                       2.7814e-02,  5.6368e-02,  8.1202e-02,  7.0822e-02,  4.7592e-03,\n",
       "                       3.1322e-02,  3.9865e-02, -2.2044e-02,  2.2731e-02,  4.4243e-03,\n",
       "                       4.8679e-02,  7.4333e-02,  4.6322e-02,  1.9210e-03,  2.8697e-02,\n",
       "                       2.8203e-02, -4.8155e-02,  5.9797e-02,  2.2293e-03,  9.3992e-02,\n",
       "                       5.2398e-02, -8.1813e-03,  7.2970e-02,  3.8366e-03,  6.3157e-03,\n",
       "                      -2.5160e-02, -9.5180e-02, -1.9564e-02,  7.1005e-02,  6.1030e-02,\n",
       "                      -5.2850e-03, -4.9797e-02,  3.7195e-02,  4.2340e-02, -4.9635e-02,\n",
       "                      -9.8979e-03,  1.4495e-02,  7.7402e-02,  3.2636e-04,  5.5682e-02,\n",
       "                      -1.0077e-02, -5.4275e-03,  1.3168e-02,  1.4878e-04, -2.3342e-02,\n",
       "                       1.5591e-02, -4.9159e-02, -7.9624e-02, -5.8363e-02,  2.3428e-03,\n",
       "                       6.1105e-02,  4.4534e-02, -6.0721e-02,  2.1248e-03, -4.1921e-02,\n",
       "                      -2.1920e-02, -9.7313e-03, -2.7119e-03, -7.7216e-03,  4.0836e-03,\n",
       "                      -7.2572e-02,  1.8075e-02,  2.2543e-02, -9.4616e-03, -4.2926e-02,\n",
       "                      -2.7971e-02, -1.6419e-02,  2.7849e-02,  5.5963e-02, -1.0204e-02,\n",
       "                      -4.1241e-02, -2.9133e-02,  1.5600e-02, -1.0383e-02,  6.7635e-04,\n",
       "                      -6.1053e-02, -3.6990e-02,  6.1936e-02, -3.3984e-02,  7.2962e-04,\n",
       "                       2.8295e-02, -2.5257e-02,  3.4256e-02, -5.7723e-02,  1.0251e-02,\n",
       "                       2.0352e-02,  1.9553e-02, -6.0159e-02, -4.7136e-02,  5.0064e-02,\n",
       "                       1.7990e-02, -3.6023e-02,  2.6908e-02,  6.1123e-04,  3.4059e-02,\n",
       "                      -4.6230e-02,  1.8684e-02, -8.2235e-03, -6.7436e-02, -4.8185e-02,\n",
       "                      -1.3584e-02,  6.9517e-02, -4.5079e-02, -3.2276e-02, -7.4670e-02,\n",
       "                      -9.9587e-03,  6.1833e-02,  5.4682e-03,  3.6957e-02,  4.0596e-02,\n",
       "                       9.1030e-02,  3.3514e-02,  5.1015e-03, -5.4838e-02, -1.7667e-03,\n",
       "                       2.2573e-02, -7.5461e-02,  2.4072e-02,  4.4668e-03, -5.6145e-03,\n",
       "                       9.8725e-03, -7.1703e-02,  2.9698e-02,  1.1013e-02,  7.7373e-02,\n",
       "                      -5.3377e-02, -2.3053e-02,  3.5809e-02, -5.6267e-02, -3.2838e-02,\n",
       "                       3.4490e-02, -4.1780e-02, -2.0002e-02, -2.0890e-02,  3.2013e-02,\n",
       "                       4.0766e-02,  3.6059e-02, -1.0325e-03,  1.7804e-02, -1.8308e-02,\n",
       "                       3.2971e-02,  1.1015e-02, -5.0988e-02,  1.2949e-03,  3.0615e-02,\n",
       "                       3.2804e-02,  9.7276e-02,  1.8005e-02,  9.9341e-03,  2.1384e-02,\n",
       "                       6.4890e-03,  8.2270e-03,  3.9549e-02, -6.9479e-02,  1.6807e-03,\n",
       "                      -3.3570e-02,  4.5958e-02, -5.0643e-02, -2.6644e-02, -7.5089e-02,\n",
       "                      -2.5819e-02,  1.7601e-02, -1.9162e-02,  5.2123e-02,  1.0692e-02,\n",
       "                       4.3350e-02, -2.3226e-02, -1.4841e-02,  1.7385e-02, -1.1760e-02,\n",
       "                       1.6810e-02,  1.9353e-02,  5.1759e-03,  1.6140e-02, -3.3761e-02,\n",
       "                      -4.1232e-02, -1.2169e-02, -2.5354e-02,  2.6974e-02,  2.0379e-02,\n",
       "                      -6.6434e-03, -4.8190e-02, -3.1476e-02, -3.4587e-02, -5.3549e-03,\n",
       "                       7.9371e-03, -2.4192e-02,  1.5705e-02,  6.9553e-02, -4.5690e-03,\n",
       "                      -1.1981e-02, -1.3942e-02,  6.6257e-02, -4.8439e-03, -1.4793e-02,\n",
       "                       2.0257e-02, -4.3009e-03,  1.5782e-02,  4.8362e-02, -8.8555e-03,\n",
       "                      -7.0531e-03,  1.0293e-02, -2.4215e-02,  2.4187e-02,  1.2405e-02,\n",
       "                       9.6969e-02,  4.4712e-02,  4.3272e-02,  1.1961e-02,  2.4818e-02,\n",
       "                       2.0086e-02,  6.7887e-02, -1.2512e-02,  4.1494e-02, -3.0966e-02,\n",
       "                       1.8339e-03, -1.9930e-02,  4.4162e-02, -5.9523e-02, -3.4157e-02,\n",
       "                       4.9923e-02, -2.4440e-03,  4.9658e-02, -2.4043e-02, -3.1375e-02,\n",
       "                       2.0800e-02,  4.0897e-02,  7.8295e-03, -1.4695e-02,  1.0505e-02,\n",
       "                      -2.3646e-02, -9.0386e-02, -1.7111e-02,  6.0729e-03,  1.5646e-02,\n",
       "                      -5.5938e-02,  7.1871e-02,  4.3828e-02,  4.2303e-02, -4.9828e-02,\n",
       "                       1.1999e-03,  2.2592e-02,  4.2724e-02,  1.4802e-02, -2.5230e-02,\n",
       "                      -2.9248e-02,  1.2479e-02,  1.3358e-02, -4.3353e-02,  1.1484e-03,\n",
       "                       8.0135e-03,  1.1942e-02, -1.3667e-02, -8.6670e-02, -3.2755e-02,\n",
       "                       5.9429e-02, -8.9545e-02,  1.6806e-02, -3.5789e-02, -2.1187e-02,\n",
       "                      -3.1238e-03, -2.7259e-02,  4.3052e-02,  2.8819e-02,  1.9043e-02,\n",
       "                       7.0653e-02,  2.0596e-03,  3.4071e-02,  2.7629e-02, -5.6857e-03,\n",
       "                       4.6982e-02, -6.5638e-02, -4.8885e-02,  6.1574e-02, -6.1337e-02,\n",
       "                      -2.8377e-02, -3.7819e-02, -6.7257e-02,  1.6500e-02,  1.2177e-02,\n",
       "                       4.3879e-03,  9.1403e-03, -5.2928e-03, -5.7071e-02, -3.6195e-03,\n",
       "                      -6.5818e-03, -3.6355e-02,  1.9170e-02,  4.5467e-02, -1.6252e-02,\n",
       "                      -6.7357e-02, -2.7740e-02,  7.6369e-03,  1.9699e-02,  4.0666e-02,\n",
       "                      -5.0907e-02,  1.4442e-02, -6.4132e-02, -1.9636e-02,  1.6171e-02,\n",
       "                       6.7794e-03,  3.3898e-02,  1.7376e-02, -1.4453e-02,  8.8365e-02,\n",
       "                      -6.1823e-02,  5.6668e-02,  1.9574e-03,  5.2425e-04,  3.8413e-02,\n",
       "                       5.7127e-02,  2.8363e-02, -6.4821e-03, -1.3724e-02, -4.2865e-02,\n",
       "                      -2.7357e-02,  7.9089e-02, -2.5681e-02,  3.3582e-02, -1.2889e-02,\n",
       "                      -2.6997e-02,  1.5823e-02, -3.9736e-02,  5.7712e-02, -1.2782e-01,\n",
       "                      -3.2262e-02, -3.0070e-02,  1.3919e-02,  5.0403e-03,  3.4185e-04,\n",
       "                       6.7240e-03,  6.9106e-02, -4.6834e-02, -4.4338e-02, -2.6605e-03,\n",
       "                       9.1921e-04, -1.2928e-02,  1.8888e-02, -3.0374e-02, -4.3989e-02,\n",
       "                       1.3997e-02, -7.0482e-02,  1.2829e-02,  5.2367e-02,  4.7506e-02,\n",
       "                      -1.0763e-02,  4.4822e-03,  7.1102e-03,  9.0900e-02,  3.0212e-02,\n",
       "                       4.4100e-02,  2.5486e-02,  1.1025e-03, -3.3566e-02, -1.3164e-02,\n",
       "                       1.5911e-02,  4.7603e-02, -2.0593e-02, -4.6480e-02,  4.4797e-02,\n",
       "                       3.2107e-02, -4.5674e-03, -3.9843e-02,  3.1874e-02, -8.6071e-02,\n",
       "                       2.3072e-02,  1.0662e-01,  1.0597e-02, -7.4918e-02, -6.2516e-02,\n",
       "                      -9.4805e-03, -2.8602e-02, -2.5443e-02, -2.9165e-02,  2.1904e-02,\n",
       "                      -9.2085e-03, -4.5607e-02, -3.0631e-02, -6.5663e-02, -1.1233e-02,\n",
       "                      -1.7162e-02,  7.7891e-03,  1.0521e-03, -5.0914e-02, -5.2292e-02,\n",
       "                       5.6281e-02, -6.8192e-02, -3.9006e-02, -7.3855e-03,  3.5439e-02,\n",
       "                      -7.6814e-02,  8.9088e-02, -5.3882e-02,  5.7954e-02, -3.9416e-03,\n",
       "                       6.4734e-03, -1.4984e-02, -1.9290e-02, -2.5070e-02,  1.3072e-02,\n",
       "                      -4.8253e-03, -5.0045e-02,  4.2003e-02, -3.2399e-02, -5.8490e-02,\n",
       "                      -3.1087e-02,  3.2331e-02, -8.1571e-02, -4.1678e-02, -6.0793e-02,\n",
       "                      -1.2969e-02, -1.3962e-02, -3.1507e-02,  7.7110e-02, -1.4803e-02,\n",
       "                      -5.2158e-03,  2.9339e-02,  1.7978e-02,  9.0293e-03,  4.1112e-03,\n",
       "                       5.2086e-02, -5.0783e-02,  1.2898e-02,  5.3244e-03,  3.0549e-02,\n",
       "                      -2.6353e-03, -3.7886e-02, -2.1694e-02, -7.2116e-02,  9.9046e-02,\n",
       "                       3.9007e-02, -6.7618e-03, -7.6537e-03,  4.6472e-02,  3.2932e-03,\n",
       "                       3.0386e-02,  3.0596e-02,  1.3805e-02, -8.5268e-03, -3.9807e-02,\n",
       "                       3.5236e-02, -1.5378e-02,  5.0764e-02,  2.6262e-02,  5.2410e-02,\n",
       "                      -4.4734e-02, -7.0689e-03,  3.4829e-03, -2.9524e-02, -3.4786e-02,\n",
       "                      -2.5906e-02,  5.1699e-02,  2.4608e-02, -2.8383e-02,  1.6143e-02,\n",
       "                       2.4456e-02,  2.3474e-02,  8.6343e-03,  3.4202e-02, -7.4420e-02,\n",
       "                      -8.2836e-02, -1.7036e-02, -3.7576e-03,  4.4460e-02,  5.7146e-02,\n",
       "                       2.3455e-02, -8.4088e-02,  3.5039e-02, -4.3217e-02, -2.2620e-03,\n",
       "                       3.8028e-03, -1.3901e-02,  3.4415e-02, -3.2215e-02,  3.1676e-02,\n",
       "                       9.2276e-03, -5.2558e-03, -2.7032e-02,  5.7740e-02, -5.7791e-02,\n",
       "                      -4.8954e-02, -1.9712e-02,  2.1940e-02,  4.4908e-03, -4.2603e-03,\n",
       "                      -5.4537e-02, -4.0727e-02,  1.7836e-02,  6.8667e-03,  1.8754e-02,\n",
       "                      -6.8578e-02,  1.7735e-02, -1.0794e-01,  3.8806e-02,  4.2909e-03,\n",
       "                       1.1035e-02,  1.7470e-02,  5.8209e-02,  3.5994e-02, -5.8582e-02,\n",
       "                      -8.3716e-02,  2.3119e-02,  1.5166e-02, -8.3907e-02, -4.4777e-04,\n",
       "                       2.3730e-02,  3.2229e-02,  1.2620e-03, -5.9052e-02,  1.9595e-02,\n",
       "                       3.9400e-02, -4.1470e-02,  9.0446e-02,  3.9856e-02, -2.3699e-02,\n",
       "                       1.6538e-02,  9.3401e-02,  2.8785e-02,  7.8217e-02, -4.7205e-02,\n",
       "                       6.5295e-02, -2.1361e-02,  2.7286e-02,  3.2624e-02, -4.5698e-02,\n",
       "                      -5.2042e-02, -1.9167e-03,  3.9249e-03, -4.7878e-03,  1.0611e-02,\n",
       "                       2.9237e-02, -2.0126e-02, -3.8684e-03, -3.6202e-02, -5.7115e-02,\n",
       "                      -2.0005e-02, -3.1333e-02,  2.3674e-02, -2.5287e-03,  2.8660e-02,\n",
       "                       1.0618e-03,  7.8037e-02, -1.1314e-02, -7.5050e-03, -4.6502e-02,\n",
       "                       5.3935e-02, -2.2223e-02, -5.4530e-02, -5.4855e-02,  7.4126e-02,\n",
       "                      -3.4650e-02, -4.5866e-02, -3.2582e-02,  5.3413e-02,  4.6316e-03,\n",
       "                      -4.9685e-02,  4.2680e-02, -2.7393e-02, -3.5262e-02,  7.3945e-02,\n",
       "                       4.2510e-02, -3.5809e-02, -5.8610e-02, -2.3892e-02, -1.6368e-02,\n",
       "                       2.3846e-02,  2.8960e-02, -3.6992e-02,  4.2212e-02,  1.1057e-02,\n",
       "                      -2.0291e-03,  1.7055e-02, -2.4150e-02, -1.8430e-02,  2.5839e-02,\n",
       "                      -1.6391e-02, -4.8495e-02,  6.9355e-02,  2.4392e-02, -1.2016e-02,\n",
       "                      -2.1766e-02, -2.2583e-02, -6.0220e-02,  2.3011e-02,  3.5264e-02,\n",
       "                      -8.1547e-02, -2.2553e-02,  4.3313e-02,  1.2492e-02, -4.7821e-02,\n",
       "                      -4.8278e-02,  3.8068e-02, -4.1910e-02,  1.1637e-03,  5.3830e-02,\n",
       "                      -5.8126e-02,  4.0403e-03, -1.2240e-02, -8.9091e-02,  6.3664e-03,\n",
       "                       3.6710e-02,  2.0045e-02, -7.3383e-02,  7.7642e-02,  8.1461e-03,\n",
       "                       3.5826e-02, -6.0466e-03, -3.0242e-02,  5.9364e-02,  5.8648e-02,\n",
       "                       2.3394e-02,  4.7526e-02, -3.9657e-03,  4.0087e-03, -2.3659e-02,\n",
       "                       1.9267e-02,  1.5585e-02, -6.9881e-02,  2.4043e-02, -1.0104e-02,\n",
       "                      -8.0235e-03,  4.0383e-02, -1.9122e-02, -4.2138e-02, -4.5537e-02,\n",
       "                      -3.8215e-02,  2.2938e-02, -4.2621e-02, -3.0479e-02, -1.8874e-02,\n",
       "                       4.1423e-02,  3.4218e-02, -6.4125e-03, -2.1867e-02,  1.0396e-02,\n",
       "                      -1.7367e-02,  4.6069e-02, -5.3235e-02, -5.6132e-03,  1.1752e-02,\n",
       "                      -4.5534e-02, -7.5036e-02,  8.3941e-03, -1.3782e-02, -3.7198e-02],\n",
       "                     device='cuda:2')),\n",
       "             ('classifier.5.weight',\n",
       "              tensor([[-1.6172e-03,  1.6792e-01, -1.7262e-01, -2.0344e-01, -3.7064e-02,\n",
       "                        5.1192e-04,  5.2234e-03, -4.0981e-02, -1.1499e-01,  5.7716e-03,\n",
       "                        6.6503e-02, -5.7098e-02,  3.4521e-02, -5.6106e-02, -3.7532e-02,\n",
       "                        4.1479e-05, -4.1539e-02, -2.0269e-02,  4.8755e-03, -3.0782e-02,\n",
       "                        2.4793e-02,  6.7479e-02,  2.5769e-02, -1.8529e-02, -8.1939e-03,\n",
       "                       -2.5712e-03, -2.3632e-02,  3.1719e-04, -1.3004e-01, -1.2981e-01,\n",
       "                       -1.2256e-02, -4.4123e-04, -9.5802e-04, -5.6681e-02, -6.8390e-02,\n",
       "                        1.2251e-02, -7.7187e-02, -5.7392e-02,  3.7257e-02, -1.3814e-01,\n",
       "                        8.3160e-04, -1.9591e-02, -7.4237e-03, -2.7604e-02, -1.8795e-03,\n",
       "                        1.5756e-02,  1.6439e-02,  2.1077e-03,  1.2852e-01, -7.9038e-02,\n",
       "                       -2.2436e-02,  2.7054e-02, -1.0083e-01,  3.6556e-02, -2.0468e-03,\n",
       "                        1.4564e-02, -1.4191e-01, -2.5805e-02,  7.2365e-02, -4.8600e-02,\n",
       "                        8.3512e-03,  5.2466e-02, -3.4240e-03,  1.7634e-03, -3.6534e-02,\n",
       "                       -1.5057e-02,  2.6217e-02,  3.0829e-03, -2.2135e-03,  1.9952e-01,\n",
       "                        1.4297e-02, -7.9975e-02, -9.9354e-02,  1.9925e-03,  1.2179e-01,\n",
       "                       -4.6654e-02,  7.8537e-04,  7.0238e-02,  2.3679e-02,  3.6155e-02,\n",
       "                        2.3538e-02,  1.8946e-01, -1.0658e-01,  9.8358e-03,  5.5285e-04,\n",
       "                       -9.1829e-02,  3.6480e-02,  6.2921e-02, -5.8982e-02, -2.1135e-01,\n",
       "                       -2.7930e-02,  2.1176e-02, -4.2491e-02,  5.3546e-03,  2.4223e-03,\n",
       "                        1.3874e-02, -1.0440e-01, -2.1332e-01,  1.8631e-03, -3.9650e-02,\n",
       "                        6.4099e-03, -3.9056e-02, -7.7863e-02,  1.5431e-01, -1.0780e-01,\n",
       "                       -5.5498e-02,  8.7391e-03,  5.2182e-03,  7.7126e-03, -5.2360e-02,\n",
       "                        3.7038e-02, -4.4434e-02, -3.1700e-02, -2.9400e-03, -5.3807e-02,\n",
       "                       -9.8207e-02, -1.3436e-01,  1.6201e-01,  2.4985e-02, -1.6029e-01,\n",
       "                       -4.9272e-02,  4.0316e-02, -1.8990e-02, -6.1887e-02, -6.0395e-02,\n",
       "                       -6.9803e-02, -7.1237e-02, -5.6251e-02,  4.9201e-04, -6.4130e-02,\n",
       "                       -6.3492e-03,  1.2099e-01, -6.4930e-05,  2.0326e-03, -6.3109e-02,\n",
       "                        7.0212e-04,  4.6590e-03, -3.7446e-03, -5.0887e-02,  4.0508e-03,\n",
       "                        7.3008e-04,  1.3211e-03, -1.3029e-01,  8.6495e-02, -6.8724e-02,\n",
       "                       -1.3772e-01,  1.1043e-01, -2.7107e-02, -7.3791e-03,  9.0973e-04,\n",
       "                        1.5724e-02,  4.9972e-03, -2.0710e-01, -3.9148e-04, -1.9936e-01,\n",
       "                        1.5060e-03,  1.9433e-01, -8.8491e-04,  4.4411e-02,  4.8098e-02,\n",
       "                       -4.4272e-02,  2.0276e-02, -2.6826e-03,  5.4553e-03,  1.3064e-01,\n",
       "                        1.1965e-02,  4.2979e-03, -7.5640e-02,  2.4736e-02,  1.0786e-02,\n",
       "                        9.1025e-03, -1.2567e-01,  5.9331e-02, -1.1296e-01,  2.0822e-02,\n",
       "                       -5.2560e-02,  1.0643e-01,  1.2385e-03,  2.4649e-02, -1.3995e-03,\n",
       "                        1.2089e-04,  1.3626e-02, -8.5954e-03, -2.2296e-03,  3.7832e-02,\n",
       "                       -3.6038e-02,  1.7663e-01,  4.4294e-02, -2.6037e-04,  4.8206e-02,\n",
       "                       -2.2953e-03, -1.3233e-02, -5.8833e-02, -1.3943e-01, -1.6554e-03,\n",
       "                       -4.8880e-02,  1.1470e-01, -2.8251e-03, -6.0940e-02, -1.7620e-03,\n",
       "                       -3.5003e-05, -3.4828e-02, -2.2855e-02,  2.2291e-01, -1.2932e-02,\n",
       "                        5.6412e-03, -1.5497e-02, -1.2355e-02,  5.5014e-02,  4.0194e-03,\n",
       "                       -1.6196e-01,  2.9218e-04, -4.5676e-03,  1.2124e-03,  1.1776e-02,\n",
       "                        6.9795e-02,  4.2809e-02,  2.7475e-03, -2.9195e-03, -3.3337e-02,\n",
       "                       -1.7885e-02,  6.6876e-04, -1.9746e-01,  1.9439e-01,  2.3023e-03,\n",
       "                        3.8639e-02,  1.1123e-03, -6.7182e-02,  7.0487e-02, -4.3511e-02,\n",
       "                        1.1904e-03,  5.4689e-02,  1.1425e-02, -1.4703e-02,  6.8638e-05,\n",
       "                        7.7217e-02, -1.4572e-02, -1.3205e-03, -7.0425e-03, -4.5694e-03,\n",
       "                        1.2979e-02, -3.9326e-02, -8.2284e-02, -3.0251e-03,  1.4361e-01,\n",
       "                       -3.9524e-03, -1.2138e-01, -3.8573e-03, -7.3526e-02, -6.0377e-02,\n",
       "                        1.1850e-01, -4.3733e-02, -5.3307e-03, -2.0428e-02,  4.7228e-03,\n",
       "                       -1.1163e-02, -5.7846e-04, -2.4536e-01, -8.0413e-02, -3.0673e-02,\n",
       "                        3.1416e-03, -1.1535e-01,  4.1488e-02, -2.3843e-01, -4.5951e-04,\n",
       "                        2.3036e-03,  2.3443e-02,  1.6700e-01,  2.6858e-02, -4.0105e-03,\n",
       "                        3.7018e-03,  2.7538e-03, -4.0901e-02, -6.5274e-03, -1.3114e-02,\n",
       "                        1.9372e-02, -1.4242e-03,  1.4197e-01, -1.4395e-02, -1.3931e-01,\n",
       "                        3.3715e-03, -8.1527e-02,  3.4053e-02, -1.9284e-03, -2.0100e-04,\n",
       "                       -1.0707e-02, -3.0279e-02, -5.4165e-02,  1.3294e-03, -6.9204e-02,\n",
       "                        4.0147e-02, -5.4517e-02,  1.0404e-01,  7.1831e-02, -1.4671e-01,\n",
       "                        1.2056e-01, -4.6357e-03, -3.2405e-02,  5.9141e-03,  2.2242e-01,\n",
       "                       -4.9276e-03,  7.8903e-03, -1.4168e-01,  1.6443e-02, -1.4096e-01,\n",
       "                        1.5970e-01, -4.5491e-02, -3.9021e-02,  3.1323e-03,  1.4264e-01,\n",
       "                        2.1982e-02,  1.7542e-02,  2.1415e-01,  1.8213e-03,  1.5959e-02,\n",
       "                       -2.5548e-02, -6.4072e-02, -6.9726e-02, -1.1172e-01, -1.0844e-03,\n",
       "                        9.8791e-02,  1.9514e-02,  2.4007e-02,  5.3827e-03, -2.3100e-02,\n",
       "                       -3.8920e-03,  2.1776e-02,  1.6853e-01, -6.9962e-02,  2.0871e-02,\n",
       "                       -4.2631e-02, -1.5461e-02,  7.0707e-02,  1.1071e-02,  6.7623e-04,\n",
       "                       -1.8144e-03,  4.5989e-03, -3.6853e-04,  1.6699e-02,  6.6564e-02,\n",
       "                        1.4289e-02,  3.4177e-02,  4.1625e-02, -3.2862e-03, -2.9603e-04,\n",
       "                        4.8223e-02, -3.4911e-02,  1.3355e-01, -2.1074e-03, -8.1021e-03,\n",
       "                        1.6710e-02,  4.2281e-02,  4.1311e-02,  5.2627e-02,  1.2581e-02,\n",
       "                        7.2190e-02, -1.2400e-01,  5.0080e-03, -1.5071e-01, -1.4366e-02,\n",
       "                        9.4606e-02,  1.5390e-01,  9.6623e-02, -3.1197e-03,  2.7270e-02,\n",
       "                        6.4494e-03, -4.1086e-04, -3.0652e-02, -1.8589e-02, -5.9055e-02,\n",
       "                       -1.4499e-01,  4.0703e-04, -1.2176e-02, -1.4902e-01, -1.8129e-01,\n",
       "                       -1.1613e-02, -1.2607e-02, -2.3249e-01, -9.9855e-02,  7.2092e-04,\n",
       "                       -1.6675e-01,  2.1557e-01, -1.6416e-01, -5.1607e-03, -2.0430e-02,\n",
       "                        4.3734e-02, -3.0071e-03, -1.5781e-02, -5.0598e-02,  7.1283e-02,\n",
       "                        1.6061e-01, -2.6566e-02, -6.1929e-02,  5.2121e-03, -1.2542e-01,\n",
       "                       -4.6985e-02, -1.6924e-01,  1.4257e-03,  3.5026e-03, -4.1667e-02,\n",
       "                       -2.9888e-02, -3.0674e-04,  7.5906e-02,  1.1077e-01, -2.3849e-03,\n",
       "                       -5.8011e-03,  2.4396e-01,  4.7562e-02,  1.9341e-02, -2.1327e-01,\n",
       "                        1.2724e-01, -3.0223e-02,  8.8745e-02,  1.3239e-01,  2.6483e-02,\n",
       "                        5.6392e-02, -8.1858e-02, -1.3195e-02, -3.0853e-03,  3.4289e-03,\n",
       "                       -2.0030e-03,  1.9651e-02, -1.4766e-01, -2.0300e-03,  4.5121e-03,\n",
       "                        2.0827e-03,  1.4635e-02,  3.3282e-02,  8.6384e-02, -1.6295e-02,\n",
       "                        1.3390e-01, -3.9489e-03,  7.1472e-02, -3.0313e-01, -4.5585e-03,\n",
       "                       -2.2789e-02,  7.0349e-02, -5.1206e-03,  2.2439e-03,  1.5272e-02,\n",
       "                        9.4522e-02, -1.1272e-02,  5.5373e-02,  5.9466e-02, -1.7543e-01,\n",
       "                       -6.7009e-02,  1.2316e-01, -1.2820e-01, -5.4679e-03,  1.1006e-01,\n",
       "                       -3.8731e-04,  4.0048e-02,  3.0705e-03,  2.1798e-03,  1.5659e-01,\n",
       "                       -5.5227e-02,  6.9088e-03,  7.1907e-02,  1.4386e-01,  2.2119e-01,\n",
       "                       -5.3237e-02, -5.8914e-02,  1.2850e-01, -1.0912e-01, -4.3910e-02,\n",
       "                       -2.4389e-01, -3.5872e-03, -6.6239e-02, -2.2427e-03,  2.8451e-02,\n",
       "                        1.0721e-01,  1.3041e-01, -6.9883e-02,  6.6121e-02,  3.0229e-02,\n",
       "                       -3.4228e-03,  8.1681e-02, -8.8208e-02, -1.8281e-03, -1.6575e-01,\n",
       "                       -1.5622e-02,  2.1476e-01,  5.4115e-02,  2.0705e-03,  1.7766e-02,\n",
       "                       -1.5063e-02,  2.7467e-03, -4.5577e-02,  5.9911e-03, -1.1422e-03,\n",
       "                        3.5033e-03, -4.2012e-03,  2.5317e-02, -6.6725e-02, -2.7901e-02,\n",
       "                        2.5702e-02, -1.2999e-02,  8.2964e-04, -9.1105e-02, -6.9126e-02,\n",
       "                       -3.7511e-03, -2.0054e-01,  1.4735e-03, -6.1502e-02, -2.8734e-04,\n",
       "                        8.1549e-03,  1.1601e-01, -1.5110e-02,  2.0336e-01, -4.8123e-03,\n",
       "                        1.9619e-02, -6.4409e-03, -8.1730e-02, -6.4524e-02,  1.2217e-01,\n",
       "                        1.3684e-02,  3.7168e-02,  1.5723e-02,  5.7033e-02,  4.7114e-03,\n",
       "                       -1.6610e-03, -2.4926e-02,  2.3594e-03, -3.1128e-02, -1.2497e-01,\n",
       "                        2.6780e-02, -1.0778e-02, -2.1446e-02,  4.1255e-02,  1.5614e-02,\n",
       "                       -1.2312e-02,  7.7947e-03,  6.4276e-03, -1.6770e-01, -1.2903e-01,\n",
       "                        4.0395e-02,  5.0241e-04,  2.1040e-03,  9.1419e-02, -1.1030e-03,\n",
       "                       -1.0595e-01,  1.1676e-02, -4.6716e-03, -3.4618e-02, -1.0512e-03,\n",
       "                        2.0474e-02, -1.2544e-01, -2.8440e-02, -5.0034e-03, -5.1233e-02,\n",
       "                        1.1864e-01,  1.0147e-01, -1.0237e-01, -2.1485e-03,  9.7034e-02,\n",
       "                        7.1581e-02,  4.8644e-02,  7.9218e-02, -2.6980e-02, -8.1270e-02,\n",
       "                       -6.0744e-03, -5.5858e-03, -4.1045e-03, -1.6696e-03,  2.8352e-02,\n",
       "                       -1.7499e-03, -5.4597e-02, -1.0360e-01, -6.5045e-02, -1.0469e-03,\n",
       "                       -1.0205e-02, -5.6046e-02, -3.3115e-03,  1.3343e-01,  5.6312e-03,\n",
       "                       -2.9124e-03, -8.4201e-02, -1.9797e-02, -7.0976e-02, -1.1005e-02,\n",
       "                        8.6118e-03, -1.7128e-01,  7.4766e-04, -3.1298e-02, -1.0108e-02,\n",
       "                        1.2682e-02,  5.1869e-02, -7.8915e-02, -7.5547e-02,  1.9143e-03,\n",
       "                        2.4378e-01, -7.1035e-02, -5.2337e-02, -2.9174e-02,  3.7454e-04,\n",
       "                        5.0342e-02,  3.7379e-02, -1.3719e-01, -3.5051e-03,  1.3426e-01,\n",
       "                        2.5345e-03,  5.7054e-03, -9.0285e-03,  9.9748e-03,  7.2957e-03,\n",
       "                       -6.7640e-02,  3.2311e-02, -6.7889e-02,  1.7917e-01,  4.2430e-02,\n",
       "                       -1.0528e-02,  1.5172e-01,  1.9130e-03, -2.2217e-02, -4.2469e-02,\n",
       "                        1.2997e-01, -5.5632e-04,  2.3430e-02,  7.0200e-03,  1.4345e-02,\n",
       "                       -7.5899e-02,  1.6967e-03, -7.6219e-02, -5.4448e-02, -1.8469e-03,\n",
       "                       -5.5804e-04, -2.1728e-04,  5.8536e-02,  4.0946e-04,  9.8226e-02,\n",
       "                        1.0915e-01,  1.4695e-03,  1.7856e-02,  5.4012e-02, -7.2323e-03,\n",
       "                       -4.1389e-02,  7.9266e-02, -1.2351e-01,  3.0032e-01, -2.3980e-02,\n",
       "                        3.3610e-02,  1.1948e-01,  1.7705e-02, -7.3071e-02, -4.6336e-02,\n",
       "                       -1.1347e-01,  3.9184e-04, -1.1145e-01,  5.3005e-02, -5.4494e-03,\n",
       "                       -8.6808e-02, -1.3003e-03,  2.4056e-02,  2.8510e-03,  2.3234e-02,\n",
       "                        1.6582e-02,  6.7293e-02, -1.0623e-02,  2.0917e-01, -7.2821e-02,\n",
       "                        1.0046e-01, -3.2857e-02, -4.9826e-02, -2.0813e-04, -1.3683e-02,\n",
       "                       -3.8811e-02, -3.7224e-02, -2.4229e-02, -1.9992e-01, -1.6560e-03,\n",
       "                        1.3044e-01, -1.1627e-01,  3.6138e-02, -2.3061e-02,  9.4071e-02,\n",
       "                        6.9903e-03,  1.2789e-02, -3.7845e-03,  2.4095e-02,  1.0610e-01,\n",
       "                        2.9766e-03,  3.0877e-02, -3.3452e-02, -3.8291e-03,  1.0249e-01,\n",
       "                        2.6145e-04, -5.8489e-02, -1.3435e-01,  1.4551e-02, -4.9768e-02,\n",
       "                       -4.2914e-02, -3.9621e-03,  1.1929e-02,  3.8895e-02,  2.0124e-01,\n",
       "                        2.0170e-02,  1.2574e-01,  3.7860e-02, -1.0153e-01, -9.0112e-03,\n",
       "                        2.0334e-01,  1.8223e-01,  2.6089e-02, -4.9414e-02,  6.0973e-02,\n",
       "                        2.1723e-04, -3.4648e-02,  3.0059e-02,  2.5719e-02,  1.7855e-02,\n",
       "                       -5.3451e-02,  5.5950e-02,  3.5146e-03, -6.2096e-04, -1.5235e-01,\n",
       "                       -5.2144e-02,  2.7637e-03,  8.5889e-02, -1.3163e-02,  1.1451e-01,\n",
       "                       -7.4939e-02, -1.0680e-02, -2.0401e-03,  2.3987e-02, -2.5693e-02,\n",
       "                       -2.0759e-03, -1.1514e-01, -1.5559e-03,  5.7494e-02, -2.0473e-02,\n",
       "                       -1.3229e-02, -4.3327e-02, -2.0693e-03,  1.0117e-01,  1.7520e-01,\n",
       "                       -3.6008e-03,  8.1386e-02,  6.3654e-03,  4.2492e-04, -3.4967e-02,\n",
       "                        1.3983e-01, -4.8110e-03, -3.4934e-02,  5.4108e-02, -7.6592e-02,\n",
       "                        3.0551e-01, -1.2888e-01, -5.1222e-03,  2.2707e-02,  9.6463e-03,\n",
       "                       -2.5069e-02,  1.5070e-01,  1.5163e-01, -7.4527e-02, -1.1467e-02,\n",
       "                        5.0734e-03,  6.9403e-02, -2.8072e-02, -4.0871e-02, -3.6835e-04,\n",
       "                        8.6619e-02, -1.0315e-01,  1.9644e-01,  1.4015e-01,  6.6164e-02,\n",
       "                       -1.2115e-01, -1.4008e-01,  6.1995e-02, -1.2951e-01, -1.0442e-02,\n",
       "                       -2.0685e-02, -1.8054e-03, -6.9363e-02, -1.8826e-02, -1.2235e-03,\n",
       "                        9.5589e-04, -3.7341e-03, -1.8395e-02, -3.6456e-04, -5.6904e-03,\n",
       "                       -1.1510e-02, -2.7633e-03,  2.0545e-02,  1.9306e-03, -7.7143e-02,\n",
       "                       -2.0583e-01, -1.3747e-02, -5.1773e-02, -1.0814e-02, -1.7156e-02,\n",
       "                        9.1234e-02,  8.9593e-03, -1.6603e-01, -1.7060e-01,  2.6329e-03,\n",
       "                       -1.4696e-01,  2.9873e-02,  3.4998e-01, -1.7545e-01, -1.5332e-02,\n",
       "                        1.6281e-02,  6.8574e-03, -7.5696e-02,  8.6231e-03,  1.0859e-01,\n",
       "                        2.7932e-02,  2.1288e-02,  5.3987e-03, -2.1022e-03,  8.0869e-02,\n",
       "                        4.4381e-02,  2.6320e-02, -5.7646e-02,  1.1337e-02,  1.0779e-01,\n",
       "                        2.3500e-02, -1.4061e-01,  3.4570e-02,  1.0401e-03, -1.4224e-01,\n",
       "                        2.9427e-02,  5.2153e-02, -2.5099e-02,  4.3645e-02,  3.4380e-03,\n",
       "                        3.1167e-02, -2.9981e-02,  2.3331e-01,  3.8353e-02,  1.6078e-02,\n",
       "                       -7.9457e-04,  4.5981e-02, -1.1056e-03, -2.6672e-02, -2.5633e-03,\n",
       "                        6.0517e-02, -5.1804e-02, -1.1166e-02,  1.9243e-03, -1.9190e-02,\n",
       "                        3.3537e-02,  1.3991e-01, -1.2681e-02,  2.5277e-02,  7.3751e-02,\n",
       "                        1.5770e-01, -2.3711e-02,  1.5144e-01,  9.4560e-03,  1.1044e-01,\n",
       "                        1.7669e-04, -1.8454e-04, -3.6182e-02,  2.8869e-02, -6.3295e-02,\n",
       "                        1.6342e-02, -2.5937e-02,  4.3565e-03, -7.2594e-02, -4.8536e-03,\n",
       "                        1.6527e-01, -8.6631e-03,  2.0873e-03,  8.8931e-03, -6.6391e-03,\n",
       "                       -5.8190e-04,  1.8435e-01, -7.2321e-02,  4.3673e-02, -1.4668e-01,\n",
       "                        1.1337e-01, -5.4306e-02, -6.2142e-04, -8.6837e-02, -2.1905e-03,\n",
       "                        1.9825e-03, -4.3598e-02, -2.7280e-02,  1.5029e-02,  1.7172e-01,\n",
       "                       -1.3146e-01,  4.4865e-02,  2.2636e-03,  4.0477e-03, -2.2742e-02,\n",
       "                       -9.6654e-04,  6.0252e-03,  2.9258e-03,  1.0418e-01, -1.2923e-03,\n",
       "                       -4.3954e-02, -2.8909e-02,  7.8799e-02, -1.3635e-03, -1.0401e-02,\n",
       "                       -1.9653e-02, -1.1308e-01,  4.6443e-02, -1.1799e-03, -6.7526e-03,\n",
       "                       -1.5109e-01,  2.0261e-01, -1.9486e-02,  1.1862e-02, -1.0472e-01,\n",
       "                       -6.1349e-02,  6.9573e-02, -3.6809e-03,  3.5305e-05,  4.5418e-02,\n",
       "                       -1.0147e-03,  2.3477e-03,  1.3607e-02,  2.9301e-04, -9.0910e-04,\n",
       "                        6.0451e-02, -7.6038e-02,  3.4390e-02, -1.2767e-01, -1.6818e-02,\n",
       "                       -2.3082e-02,  5.3258e-03,  1.4697e-01,  4.1925e-02, -3.3916e-03,\n",
       "                       -1.8786e-02, -2.5643e-02, -2.4500e-01,  3.2413e-02,  4.7393e-04,\n",
       "                       -2.4402e-01, -9.5942e-02, -1.1687e-01,  4.1240e-02, -1.1155e-03,\n",
       "                        1.0186e-01,  4.7684e-02,  3.1253e-02,  3.3142e-02,  1.6246e-01,\n",
       "                       -4.2139e-02, -6.2231e-02, -1.5250e-02,  1.4258e-03,  1.4879e-03,\n",
       "                        5.1601e-02, -1.0664e-01,  3.8817e-03, -1.1687e-02, -1.3491e-01,\n",
       "                        1.9965e-01,  8.7267e-02,  1.3043e-03,  4.2133e-02, -3.0143e-02,\n",
       "                       -1.2051e-01,  7.7364e-04,  3.5362e-02, -1.3308e-02,  9.4590e-02,\n",
       "                        2.6029e-02,  2.4700e-02,  5.0970e-03, -3.6325e-02, -2.5776e-02,\n",
       "                        2.3909e-03, -2.1681e-02, -4.6903e-03,  1.2207e-02, -2.0971e-03,\n",
       "                       -1.0926e-02,  2.1187e-03,  1.4475e-02, -3.9482e-02,  5.1052e-04,\n",
       "                       -1.2460e-02, -1.2553e-01, -3.0699e-02, -7.2398e-03, -2.5422e-01,\n",
       "                       -3.3364e-03,  5.9804e-02,  7.3914e-02, -3.8590e-02,  5.2978e-04,\n",
       "                        1.3753e-03,  1.9204e-01, -1.2306e-01, -2.1854e-01, -1.9423e-01,\n",
       "                        2.1532e-03, -5.5034e-03,  1.6945e-03, -6.5501e-02, -8.9261e-02,\n",
       "                        1.3393e-02, -2.9119e-01,  4.7489e-02,  1.1951e-02,  2.2206e-03]],\n",
       "                     device='cuda:2')),\n",
       "             ('classifier.5.bias', tensor([-0.0474], device='cuda:2'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataloaders.dill', 'wb') as f:\n",
    "    dill.dump((train_dataloader, val_dataloader, test_dataloader), f)\n",
    "\n",
    "\n",
    "torch.save(caption_evaluator.state_dict(), 'caption_evaluator.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('lt2326_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd2feef55d4ee460479306887fa1cc2179f52f92e40ccb13d5bbd3870fa5c6f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
